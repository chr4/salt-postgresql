# vim: ft=conf

data_directory = '/var/lib/postgresql/{{ version }}/main'

hba_file = '/etc/postgresql/{{ version }}/main/pg_hba.conf'
ident_file = '/etc/postgresql/{{ version }}/main/pg_ident.conf'

# If external_pid_file is not explicitly set, no extra PID file is written.
external_pid_file = '/var/run/postgresql/{{ version }}-main.pid'

# Specifies the TCP/IP address(es) on which the server is to listen for connections from client
# applications. The value takes the form of a comma-separated list of host names and/or numeric IP
# addresses. The special entry * corresponds to all available IP interfaces. The entry 0.0.0.0
# allows listening for all IPv4 addresses and :: allows listening for all IPv6 addresses. If the
# list is empty, the server does not listen on any IP interface at all, in which case only Unix-
# domain sockets can be used to connect to it.
listen_addresses = '{{ listen_addresses }}'

# Specifies the directory of the Unix-domain socket(s) on which the server is to listen for
# connections from client applications. Multiple sockets can be created by listing multiple
# directories separated by commas. Whitespace between entries is ignored; surround a directory
# name with double quotes if you need to include whitespace or commas in the name. An empty
# value specifies not listening on any Unix-domain sockets, in which case only TCP/IP sockets
# can be used to connect to the server. The default value is normally /tmp, but that can be
# changed at build time. This parameter can only be set at server start.
# In addition to the socket file itself, which is named .s.PGSQL.nnnn where nnnn is the
# server's port number, an ordinary file named .s.PGSQL.nnnn.lock will be created in each of
# the unix_socket_directories directories. Neither file should ever be removed manually.
unix_socket_directories = '/var/run/postgresql'

# The TCP port the server listens on; 5432 by default. Note that the same port number is used for
# all IP addresses the server listens on.
port = 5432

{%- if ssl %}
ssl = on

{%- if ssl_ca_file %}
ssl_ca_file = '{{ ssl_ca_file }}'
{%- endif %}

{%- if ssl_ca_file %}
ssl_cert_file = '{{ ssl_cert_file }}'
{%- endif %}

{%- if ssl_ca_file %}
ssl_key_file = '{{ ssl_key_file }}'
{%- endif %}

{%- else %}
ssl = off
{%- endif %}

# Determines the maximum number of concurrent connections to the database server. When running a
# standby server, you must set this parameter to the same or higher value than on the master server.
# Otherwise, queries will not be allowed in the standby server.
max_connections = {{ max_connections }}

# make xfs usage safe (this is enabled by default)
full_page_writes = on

# Specifies whether transaction commit will wait for WAL records to be written to disk before the
# command returns a "success" indication to the client. Valid values are on, remote_write, local,
# and off. The default, and safe, setting is on. When off, there can be a delay between when success
# is reported to the client and when the transaction is really guaranteed to be safe against a
# server crash. (The maximum delay is three times wal_writer_delay.) Unlike fsync, setting this
# parameter to off does not create any risk of database inconsistency: an operating system or
# database crash might result in some recent allegedly-committed transactions being lost, but the
# database state will be just the same as if those transactions had been aborted cleanly. So,
# turning synchronous_commit off can be a useful alternative when performance is more important than
# exact certainty about the durability of a transaction.
synchronous_commit = off

# Sets the default statistics target for table columns without a column-specific target set via
# ALTER TABLE SET STATISTICS. Larger values increase the time needed to do ANALYZE, but might
# improve the quality of the planner's estimates. The default is 100.
default_statistics_target = 100

# only useful when using table partitioning
constraint_exclusion = off

# During the execution of VACUUM and ANALYZE commands, the system maintains an internal counter that
# keeps track of the estimated cost of the various I/O operations that are performed. When the
# accumulated cost reaches a limit (specified by vacuum_cost_limit), the process performing the
# operation will sleep for a short period of time, as specified by vacuum_cost_delay. Then it will
# reset the counter and continue execution.

# The intent of this feature is to allow administrators to reduce the I/O impact of these commands
# on concurrent database activity. There are many situations where it is not important that
# maintenance commands like VACUUM and ANALYZE finish quickly; however, it is usually very important
# that these commands do not significantly interfere with the ability of the system to perform other
# database operations. Cost-based vacuum delay provides a way for administrators to achieve this.
autovacuum = on
autovacuum_vacuum_cost_delay = '{{ autovacuum_vacuum_cost_delay }}'
autovacuum_vacuum_cost_limit = {{ autovacuum_vacuum_cost_limit}}

# Log autovacuum tasks that are taking longer than 500ms
log_autovacuum_min_duration = '{{ log_autovacuum_min_duration }}'

# Specifies the minimum number of updated or deleted tuples needed to trigger a VACUUM in any one
# table. The default is 50
# (This in practise only applies to very small tables)
autovacuum_vacuum_threshold = {{ autovacuum_vacuum_threshold }}

# Specifies a fraction of the table size to add to autovacuum_vacuum_threshold when deciding whether
# to trigger a VACUUM. The default is 0.2 (20% of table size).
autovacuum_vacuum_scale_factor = {{ autovacuum_vacuum_scale_factor }}

# Specifies the amount of memory to be used by internal sort operations and hash tables before
# writing to temporary disk files. Note that for a complex query, several sort or hash operations
# might be running in parallel; each operation will be allowed to use as much memory as this value
# specifies before it starts to write data into temporary files. Also, several running sessions
# could be doing such operations concurrently. Therefore, the total memory used could be many times
# the value of work_mem.
#
# work_mem * max_connections = memory is a conservative first approach.
work_mem = '{{ work_mem }}'

# If you have a dedicated database server with 1GB or more of RAM, a reasonable starting value for
# shared_buffers is 25% of the memory in your system. There are some workloads where even larger
# settings for shared_buffers are effective, but given the way PostgreSQL also relies on the
# operating system cache, it's unlikely you'll find using more than 40% of RAM to work better than a
# smaller amount. Larger settings for shared_buffers usually require a corresponding increase in
# checkpoint_segments, in order to spread out the process of writing large quantities of new or
# changed data over a longer period of time.
shared_buffers = '{{ shared_buffers }}'

# The parameter checkpoint_segments was removed with postgresql-9.5 (was: checkpoint_segments = 64)
# If you previously adjusted checkpoint_segments, the following formula will give you an approximately equivalent setting:
# max_wal_size = (3 * checkpoint_segments) * 16MB
#
# checkpoint_segments = 64 -> max_wal_size = 3072
#
# Maximum size to let the WAL grow to between automatic WAL checkpoints. This is a soft limit; WAL
# size can exceed max_wal_size under special circumstances, like under heavy load, a failing
# archive_command, or a high wal_keep_segments setting. The default is 1 GB. Increasing this
# parameter can increase the amount of time needed for crash recovery. This parameter can only be
# set in the postgresql.conf file or on the server command line.
max_wal_size = '3GB'

# Maximum time between automatic WAL checkpoints, in seconds
checkpoint_timeout = 30min

# Specifies the target of checkpoint completion, as a fraction of total time between checkpoints.
checkpoint_completion_target = 0.8

# maintenance_work_mem, should be a lot higher than work_mem
# recommended value: 50mb for each 1gb of system ram, but 50MB minimum
# also recommendation: 256 - 1024mb for large databases
maintenance_work_mem = '{{ maintenance_work_mem }}'

# Sets the planner's assumption about the effective size of the disk cache that is available to a
# single query. This is factored into estimates of the cost of using an index; a higher value makes
# it more likely index scans will be used, a lower value makes it more likely sequential scans will
# be used. When setting this parameter you should consider both PostgreSQL's shared buffers and the
# portion of the kernel's disk cache that will be used for PostgreSQL data files. Also, take into
# account the expected number of concurrent queries on different tables, since they will have to
# share the available space. This parameter has no effect on the size of shared memory allocated by
# PostgreSQL, nor does it reserve kernel disk cache; it is used only for estimation purposes. The
# system also does not assume data remains in the disk cache between queries. The default is 128
# megabytes (128MB). Should be between 0.6 and 0.8 of system ram
effective_cache_size = '{{ effective_cache_size }}'

# wal_level determines how much information is written to the WAL. The default value is minimal,
# which writes only the information needed to recover from a crash or immediate shutdown. archive
# adds logging required for WAL archiving, and hot_standby further adds information required to run
# read-only queries on a standby server.
wal_level = {{ wal_level }}

# Specifies whether or not you can connect and run queries during recovery
hot_standby = on

{% if wal_level == 'minimal' %}
# Disable wal senders when wal_level is minimal
max_wal_senders = 0

{%- else %}
# When this parameter is on, the PostgreSQL server compresses a full page image written to WAL when
# full_page_writes is on or during a base backup. A compressed page image will be decompressed
# during WAL replay. The default value is off. Only superusers can change this setting.  Turning
# this parameter on can reduce the WAL volume without increasing the risk of unrecoverable data
# corruption, but at the cost of some extra CPU spent on the compression during WAL logging and on
# the decompression during WAL replay.
wal_compression = on

# Specifies the maximum number of concurrent connections from standby servers or streaming base
# backup clients (i.e., the maximum number of simultaneously running WAL sender processes). The
# default is zero, meaning replication is disabled. WAL sender processes count towards the total
# number of connections, so the parameter cannot be set higher than max_connections. This parameter
# can only be set at server start. wal_level must be set to archive or hot_standby to allow
# connections from standby servers.
max_wal_senders = {{ max_wal_senders }}

{% if wal_buffers is defined %}
# The amount of shared memory used for WAL data that has not yet been written to disk. The default
# setting of -1 selects a size equal to 1/32nd (about 3%) of shared_buffers, but not less than 64kB
# nor more than the size of one WAL segment, typically 16MB. The contents of the WAL buffers are
# written out to disk at every transaction commit, so extremely large values are unlikely to provide
# a significant benefit. However, setting this value to at least a few megabytes can improve write
# performance on a busy server where many clients are committing at once. The auto-tuning selected
# by the default setting of -1 should give reasonable results in most cases.
wal_buffers = '{{ wal_buffers }}'
{%- endif %}

{% if wal_keep_segments is defined %}
# Specifies the minimum number of past log file segments kept in the pg_xlog directory, in case a
# standby server needs to fetch them for streaming replication. Each segment is normally 16
# megabytes. If a standby server connected to the sending server falls behind by more than
# wal_keep_segments segments, the sending server might remove a WAL segment still needed by the
# standby, in which case the replication connection will be terminated. Downstream connections will
# also eventually fail as a result. (However, the standby server can recover by fetching the segment
# from archive, if WAL archiving is in use.) This sets only the minimum number of segments retained
# in pg_xlog; the system might need to retain more segments for WAL archival or to recover from a
# checkpoint. If wal_keep_segments is zero (the default), the system doesn't keep any extra segments
# for standby purposes, so the number of old WAL segments available to standby servers is a function
# of the location of the previous checkpoint and status of WAL archiving. This parameter can only be
# set in the postgresql.conf file or on the server command line.
wal_keep_segments = {{ wal_keep_segments }}
{%- endif %}

# When this parameter is on, the PostgreSQL server writes the entire content of each disk page
# to WAL during the first modification of that page after a checkpoint, even for non-critical
#
# modifications of so-called hint bits. If data checksums are enabled, hint bit updates are
# always WAL-logged and this setting is ignored. You can use this setting to test how much
# extra WAL-logging would occur if your database had data checksums enabled.
#
# pg_rewind requires that the target server either has the wal_log_hints option enabled in
# postgresql.conf or data checksums enabled when the cluster was initialized with initdb.
# Neither of these are currently on by default. full_page_writes must also be set to on, but is
# enabled by default.
{%- if wal_log_hints %}
wal_log_hints = on
{%- else %}
wal_log_hints = off
{%- endif %}

{% if archive_command is defined %}
# When archive_mode is enabled, completed WAL segments are sent to archive storage by setting
# archive_command. archive_mode and archive_command are separate variables so that archive_command
# can be changed without leaving archiving mode.
archive_mode = on

# The shell command to execute to archive a completed WAL file segment. Any %p in the string is
# replaced by the path name of the file to archive, and any %f is replaced by only the file name.
# (The path name is relative to the working directory of the server, i.e., the cluster's data
# directory.) Use %% to embed an actual % character in the command. It is important for the command
# to return a zero exit status only if it succeeds. It is ignored unless archive_mode was enabled at
# server start. If archive_command is an empty string (the default) while archive_mode is enabled,
# WAL archiving is temporarily disabled, but the server continues to accumulate WAL segment files in
# the expectation that a command will soon be provided.
#
# From https://wiki.postgresql.org/wiki/Warm_Standby:
# You must use a command here that does atomic copies, meaning that the file will never appear
# under the destination filename until it has been completely copied over. This keeps the standby
# server from trying to read a partial file. rsync is known to work. A notable command that isn't
# atomic is scp. If you want to use scp for this purpose, you will need to transfer files into
# another directory on the secondary, then move them to where the restore command looks for them
# after the transfer is complete.
#
# --whole-file            copy files whole (w/o delta-xfer algorithm)
# --ignore-existing       skip updating files that exist on receiver
archive_command = '{{ archive_command }}'
{%- endif %}

{%- endif %}

# Sets the number of concurrent disk I/O operations that PostgreSQL expects can be executed
# simultaneously. Raising this value will increase the number of I/O operations that any individual
# PostgreSQL session attempts to initiate in parallel. The allowed range is 1 to 1000, or zero to
# disable issuance of asynchronous I/O requests. Currently, this setting only affects bitmap heap
# scans. A good starting point for this setting is the number of separate drives comprising a RAID 0
# stripe or RAID 1 mirror being used for the database. (For RAID 5 the parity drive should not be
# counted.) However, if the database is often busy with multiple queries issued in concurrent
# sessions, lower values may be sufficient to keep the disk array busy. A value higher than needed
# to keep the disks busy will only result in extra CPU overhead.
# We're using a RAID 10 array with 4 drives
# effective_io_concurrency = 4

# Controls whether a log message is produced when a session waits longer than deadlock_timeout to
# acquire a lock. This is useful in determining if lock waits are causing poor performance. The
# default is off.
log_lock_waits = on

# This is the amount of time, in milliseconds, to wait on a lock before checking to see if there is
# a deadlock condition. The check for deadlock is relatively expensive, so the server doesn't run it
# every time it waits for a lock. We optimistically assume that deadlocks are not common in
# production applications and just wait on the lock for a while before checking for a deadlock.
# Increasing this value reduces the amount of time wasted in needless deadlock checks, but slows
# down reporting of real deadlock errors. The default is one second (1s), which is probably about
# the smallest value you would want in practice. On a heavily loaded server you might want to raise
# it. Ideally the setting should exceed your typical transaction time, so as to improve the odds
# that a lock will be released before the waiter decides to check for deadlock. Only superusers can
# change this setting.  When log_lock_waits is set, this parameter also determines the length of
# time to wait before a log message is issued about the lock wait. If you are trying to investigate
# locking delays you might want to set a shorter than normal deadlock_timeout.
deadlock_timeout = '30s'

# Specifies the dynamic shared memory implementation that the server should use. Possible
# values are posix (for POSIX shared memory allocated using shm_open), sysv (for System V
# shared memory allocated via shmget), windows (for Windows shared memory), mmap (to simulate
# shared memory using memory-mapped files stored in the data directory), and none (to disable
# this feature). Not all values are supported on all platforms; the first supported option is
# the default for that platform. The use of the mmap option, which is not the default on any
# platform, is generally discouraged because the operating system may write modified pages back
# to disk repeatedly, increasing system I/O load; however, it may be useful for debugging, when
# the pg_dynshmem directory is stored on a RAM disk, or when other shared memory facilities are
# not available.
dynamic_shared_memory_type = posix

# Causes the duration of each completed statement to be logged if the statement ran for at least the
# specified number of milliseconds. Setting this to zero prints all statement durations. Minus-one
# (the default) disables logging statement durations. For example, if you set it to 250ms then all
# SQL statements that run 250ms or longer will be logged.
log_min_duration_statement = '1500ms'
log_line_prefix = '%m [%p] %q%u@%d '
log_timezone = 'Europe/Berlin'

# Controls which SQL statements are logged. Valid values are none (off), ddl, mod, and all (all statements).
# ddl logs all data definition statements, such as CREATE, ALTER, and DROP statements. mod logs all ddl
# statements, plus data-modifying statements such as INSERT, UPDATE, DELETE, TRUNCATE, and COPY FROM. PREPARE, 
# EXECUTE, and EXPLAIN ANALYZE statements are also logged if their contained command is of an appropriate type. 
{% if log_statement is defined %}
log_statement = '{{ log_statement }}'
{% else %}
log_statement = 'none'
{% endif %}

# This parameter enables the logging collector, which is a background process that captures log
# messages sent to stderr and redirects them into log files.
{% if logging_collector %}
logging_collector = on

{% if log_directory is defined %}
log_directory = '{{ log_directory }}'
{% endif %}

{% if log_filename is defined %}
log_filename = '{{ log_filename }}'
{% endif %}

{% else %}
logging_collector = off
{% endif %}

# Selects the text search configuration that is used by those variants of the text search functions
# that do not have an explicit argument specifying the configuration. The built-in default is
# pg_catalog.simple, but initdb will initialize the configuration file with a setting that
# corresponds to the chosen lc_ctype locale, if a configuration matching that locale can be
# identified.
default_text_search_config = 'pg_catalog.english'

# Sets the display format for date and time values, as well as the rules for interpreting ambiguous
# date input values. For historical reasons, this variable contains two independent components: the
# output format specification (ISO, Postgres, SQL, or German) and the input/output specification for
# year/month/day ordering (DMY, MDY, or YMD). These can be set separately or together. The keywords
# Euro and European are synonyms for DMY; the keywords US, NonEuro, and NonEuropean are synonyms for
# MDY. The built-in default is ISO, MDY, but initdb will initialize the configuration file with a
# setting that corresponds to the behavior of the chosen lc_time locale.
datestyle = 'iso, mdy'

lc_messages = 'en_US.UTF-8'
lc_monetary = 'en_US.UTF-8'
lc_numeric = 'en_US.UTF-8'
lc_time = 'en_US.UTF-8'

# This is set in the default postgresql.conf of Ubuntu
stats_temp_directory = '/var/run/postgresql/{{ version }}-main.pg_stat_tmp'
cluster_name = '{{ version }}/main'
include_dir = 'conf.d'
